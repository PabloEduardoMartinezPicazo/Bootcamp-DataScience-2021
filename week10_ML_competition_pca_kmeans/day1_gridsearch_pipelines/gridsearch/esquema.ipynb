{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### ML\n",
    "1. Datos. Detectar el tipo de problema: \n",
    "    - Clasificación: (Logistic regression, SVC, KNN,Decission Tree C,Rrandom Forest Classificator, ...) \n",
    "    - Regresión: (Regresión lineal, non-linear polinómica, SVR, Decission Tree R,Rrandom Forest Classificator R,...)\n",
    "\n",
    "2. EDA: Data wrangling: \n",
    "    - !!!!!!! Crear el modelo baseline¡¡¡¡¡¡¡ -> si este modelo sin haber hcho nada da mejores resultados es importante hacerlo\n",
    "    - Webscraping, API, Json,CSV,BBDD (SQL/NoSQL), páginas Web\n",
    "    - Feature Engineering (extraccion de caracteristicas):\n",
    "        - Outliers, regex, nan, distribuciones, estandarización (rango los datos con la media en 0 y la desviacion tipica 1 ), normalizar, encoding (dummies),duplicados, eliminar columnas no reolevantes. \n",
    "    - Visualizar datos ( Correlaciones)\n",
    "    - Variables agregadas: No hemos hecho ejercicios pero se puede hacer para buscar patrones o añadir nuevos patrones. Se agregan columnas agregadas: por ejemplo media de otras columnas  numericas \n",
    "    - Ponderaciones de columnas ( darle mas peso a una columna, mutilipoicando por 2 por 3 por 7 para darle mas valor a esa columna)\n",
    "    - Eliminar columnas colinieales (una multiplicada por 2) o una columna alturas en metros y otra en cm \n",
    "3. Maquetar los datos para que train y test tengan sentido.\n",
    "\n",
    "4. Partir los datos en conjunto de entrenamiento y test. Elegimos un % de test y semilla.\n",
    "\n",
    "5. Cross validation -> con el objetivo de saber como es el comportamientos de mi modelo para mis datos. Grid_search ya lo hace asi que es mejor hacerlo con el Grid_search. Depende del numero de filas y datos que tengas, si es muy grande no me lo entrenes simplemente dime que ta les la relacion que tienen\n",
    "\n",
    "6. Grid search pipeline ->pipeline podria estar en la parte de EDA porque ya retocamos los datos \n",
    "\n",
    "7. Nos quedamos con el mejor modelo y probamos el score con el conjunto. -> grid search no nos da con el conjunto de test solo con el de train asi que necesitamos los dos. Nos quedamos con el que mejor generalice, si ninguno es valido hay que volver arriba y elegir otro modelo.\n",
    "\n",
    "8. Guardamos para futuras pruebas y para estar relajados. \n",
    "\n",
    "9. Tras probar muchas veces con muchas semillas, tenemos un conjunto de test y de train fijados, hacemos un .fit de todo .fit(X,y) y guardamos el modelo entrenado con todos los daots, con otro nombre.\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \"\"\" para que pare un conjunto de validacion si encuentra algun trozso muy bajo\n",
    " if score_val>np.mean(val_score)//2:\n",
    "     print(\"caca de parte  de validacion\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"if i % == 1000: \n",
    "    pickle.domp(model,open(path+\"model_saved.sab\",\"wb\"))\n",
    "    \"\"\""
   ]
  }
 ]
}