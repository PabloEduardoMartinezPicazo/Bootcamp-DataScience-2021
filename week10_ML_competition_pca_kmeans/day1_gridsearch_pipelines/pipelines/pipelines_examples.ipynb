{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch & Pipelines\n",
    "GridSearch is an optimization tool that we use when tuning hyperparameters. We define the grid of parameters that we want to search through, and we select the best combination of parameters for our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - One way\n",
    "Itera un algoritmo sobre un conjunto de hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline with 4 steps"
   ]
  },
  {
   "source": [
    "SimpleImputer\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 7. ,  2. ,  3. ],\n",
       "       [ 4. ,  3.5,  6. ],\n",
       "       [10. ,  5. ,  9. ]])"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer #transformar todos los datos qque estan vacios en datos, con la estrategia que le indiques, transofrmame nan con la media -> hay el que tenga frecuencia,constante mediana,media de la columna\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp_mean.fit_transform([[7, 2, 3], [4, np.nan, 6], [10, 5, 9]])"
   ]
  },
  {
   "source": [
    "StandarScaler\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-----\n[[0, 0], [0, 0], [1, 1], [1, 1]]\n-----\n[[-1. -1.]\n [-1. -1.]\n [ 1.  1.]\n [ 1.  1.]]\n-----\n[[3. 3.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "data = [[0, 0], [0, 0], [1, 1], [1, 1]] #standarizar estos valores -> media es 0 y la desviacion tipica es 1, de una lista de valores los estandarizas\n",
    "scaler = StandardScaler()\n",
    "print(\"-----\")\n",
    "print(data)\n",
    "print(\"-----\")\n",
    "print(scaler.fit_transform(data)) #las distancias que hay entre los valores 0 y 1 en este caso cuando se transforma es 2 entonces que valdria el 2?\n",
    "print(\"-----\")\n",
    "print(scaler.transform([[2, 2]])) # pues el 2 valdria 3 porque la estandarizacion ha hecho que el 0 valga -1 y el 1 siga valiendo 1 y tienen una distancia de 2 por lo tanto si meto 2 doses el valor va a ser 3 "
   ]
  },
  {
   "source": [
    "SelectKBest\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html\n",
    "\n",
    "Chi\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html\n",
    "\n",
    "chi-square test measures dependence between stochastic variables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X.shape (1797, 64)\nX_new.shape (1797, 20)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "X, y = load_digits(return_X_y=True)\n",
    "X_new = SelectKBest(chi2, k=20).fit_transform(X, y) #quedate con las 20 columnas que tengan mÃ¡s relacion, chi quita aquellas columnas que tengan menos correlacion. o sea te quedas con las mas correlacionadas, pierdes info, no sabes hasta que punto te va a quitar la columna\n",
    "print(\"X.shape\", X.shape)\n",
    "print(\"X_new.shape\", X_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_log = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer()), \n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"selectkbest\", SelectKBest()),\n",
    "    (\"reglog\", LogisticRegression()) #transformar los nan en media, scaler es standarizar, selectkbest las mejores lineas y reglog la logisticc regression\n",
    "\n",
    "]) #pasos que vamos a hacer\n",
    "\n",
    "reg_log_param = {\n",
    "    \"imputer__strategy\": ['mean', 'median', 'most_frequent'],\n",
    "    \"reglog__penalty\": ['l1', 'l2'],\n",
    "    \"reglog__C\": [0.01, 0.1, 0.5, 1],\n",
    "    \"selectkbest__k\": [1,2,3],\n",
    "} #hay que ponerlo en un dic -> te haces referencia al artibuto que quieres probar con el doble guion bajo poner el mismo nombre que le has puesto y __ y nombre paramentro reglog__C \n",
    "\n",
    "gs_reg_log = GridSearchCV(reg_log,\n",
    "                         reg_log_param,\n",
    "                         cv = 10,\n",
    "                         scoring = 'accuracy',\n",
    "                         verbose=1,\n",
    "                         n_jobs=-1)#que nos devuelva el scoring del model de estudio uno o varios matriz, etc. n_jobs-1 es todos los nucleos del procesador y verbose =1 es menos detallado la informacion de las tareas, mas grande el verbose mas detalle\n",
    "\n",
    "grids = {\n",
    "    \"gs_reg_log\": gs_reg_log,\n",
    "} #pasarlo a un diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "#################\n",
      "NOMBRE: gs_reg_log\n",
      "#################\n",
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.1s\n",
      "Wall time: 794 ms\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed:    0.7s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for nombre, grid in grids.items():\n",
    "    print(\"#################\")\n",
    "    print(\"NOMBRE:\", nombre)\n",
    "    print(\"#################\")\n",
    "    grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         Grid  Best score\n",
       "0  gs_reg_log    0.941667"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Grid</th>\n      <th>Best score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>gs_reg_log</td>\n      <td>0.941667</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "import pandas as pd\n",
    "best_grids = [(i, j.best_score_) for i, j in grids.items()]\n",
    "\n",
    "best_grids = pd.DataFrame(best_grids,\n",
    "                         columns = ['Grid', 'Best score']).sort_values(by = 'Best score', ascending=False)\n",
    "best_grids #mejor modelos de los que has probado, solo hemos probado 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('imputer', SimpleImputer()),\n",
       "                                       ('scaler', StandardScaler()),\n",
       "                                       ('selectkbest', SelectKBest()),\n",
       "                                       ('reglog', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'imputer__strategy': ['mean', 'median',\n",
       "                                               'most_frequent'],\n",
       "                         'reglog__C': [0.01, 0.1, 0.5, 1],\n",
       "                         'reglog__penalty': ['l1', 'l2'],\n",
       "                         'selectkbest__k': [1, 2, 3]},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "best_model_grid = grids['gs_reg_log']\n",
    "best_model_grid #accedes a los valores usados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pipeline(steps=[('imputer', SimpleImputer()), ('scaler', StandardScaler()),\n                ('selectkbest', SelectKBest(k=2)),\n                ('reglog', LogisticRegression(C=0.1))])\n"
     ]
    }
   ],
   "source": [
    "print(best_model_grid.best_estimator_) #mejor estimador con los parametros ganadores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer()), ('scaler', StandardScaler()),\n",
       "                ('selectkbest', SelectKBest(k=2)),\n",
       "                ('reglog', LogisticRegression(C=0.1))])"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "best_model = grids['gs_reg_log'].best_estimator_\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1)"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "reglog_model = grids['gs_reg_log'].best_estimator_[\"reglog\"]\n",
    "reglog_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'gs_reg_log_pipeline.model'\n",
    "# Es importante guardar con el pipeline entero\n",
    "with open(filename, 'wb') as archivo_salida:\n",
    "    pickle.dump(best_model, archivo_salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer()), ('scaler', StandardScaler()),\n",
       "                ('selectkbest', SelectKBest(k=2)),\n",
       "                ('reglog', LogisticRegression(C=0.1))])"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "with open(filename, 'rb') as archivo_entrada:\n",
    "    pipeline_importada = pickle.load(archivo_entrada)\n",
    "pipeline_importada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0])"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "# Es importante quedarse con el pipeline entero\n",
    "pipeline_importada.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python374jvsc74a57bd07945e9a82d7512fbf96246d9bbc29cd2f106c1a4a9cf54c9563dadf10f2237d4",
   "display_name": "Python 3.7.4 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "metadata": {
   "interpreter": {
    "hash": "7945e9a82d7512fbf96246d9bbc29cd2f106c1a4a9cf54c9563dadf10f2237d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}